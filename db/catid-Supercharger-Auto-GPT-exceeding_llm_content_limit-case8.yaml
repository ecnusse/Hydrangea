app: Supercharger-Auto-GPT
repo: https://github.com/catid/Supercharger-Auto-GPT
commit: 2f8066fb4121ba0f724cbe92c4cbef91ecf5cc29
defect_id: catid-Supercharger-Auto-GPT-exceeding_llm_content_limit-case8
type: exceeding LLM content limit
case: '8'
consequence:
- ST
locations:
- 'scripts/config.py: token limit settings; scripts/commands.py: search_files; scripts/chat.py:
  context construction and token management'
trigger_tests:
- '1) Setup deps and OPENAI_API_KEY; 2) Set FAST_TOKEN_LIMIT=5000 (lower than default
  4000); 3) Launch: python scripts/main.py --continuous --gpt3only; 4) Configure AI
  to search and describe all files; 5) Execute search_files command on directory with
  many files (~2000 files); 6) Observe "InvalidRequestError: This model''s maximum
  context length is 8191 tokens" when large file list exceeds token limit.'
