app: Agent-LLM
repo: https://github.com/hlohaus/Agent-LLM
commit: d8a46dacea35c6224effd3e733d5c085bea1949a
defect_id: hlohaus-Agent-LLM-exceeding_llm_content_limit-/
type: Exceeding LLM content limit
case: /
consequence:
- ST
locations:
- provider/oobabooga.py, AgentLLM.py
trigger_tests:
- 1. Set MAX_TOKENS to 2000 in Agent-LLM .env file. 2. Make an API request to Oobabooga.
  3. Observe in the Oobabooga log that the context size is 2096, causing the service
  to crash.
