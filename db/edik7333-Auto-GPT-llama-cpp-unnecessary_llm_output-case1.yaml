app: Auto-GPT-llama-cpp
repo: https://github.com/edik7333/Auto-GPT-llama-cpp
commit: 2b4bf189825c0abe28bf6f020b87921d82636d67
defect_id: edik7333-Auto-GPT-llama-cpp-unnecessary_llm_output-case1
type: unnecessary LLM output
case: '1'
consequence:
- IC
- UI
locations:
- scripts/chat.py scripts/agent_manager.py
trigger_tests:
- '1.Configure and launch Auto-GPT according to the instructions on this website:
  https://docs.agpt.co/.(Use releases before v0.5.0) 2.Create an AI agent. 3.Start
  AutoGPT. Authorize these commands and observe their outputs: (1) list_files ARGUMENTS
  = {''directory'': ''....\auto_gpt_workspace''} --> SYSTEM: Failure: command list_files
  returned too much output. Do not execute this command again with the same arguments.
  (2)read_file ARGUMENTS = {''filename'': ''...smoketests_basic_qemu.yml''} --> SYSTEM:
  Failure: command read_file returned too much output. Do not execute this command
  again with the same arguments.'
