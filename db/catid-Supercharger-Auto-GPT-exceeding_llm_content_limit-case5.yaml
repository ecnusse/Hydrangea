app: Supercharger-Auto-GPT
repo: https://github.com/catid/Supercharger-Auto-GPT
commit: 2f8066fb4121ba0f724cbe92c4cbef91ecf5cc29
defect_id: catid-Supercharger-Auto-GPT-exceeding_llm_content_limit-case5
type: exceeding LLM content limit
case: '5'
consequence:
- ST
- IC
locations:
- 'scripts/config.py: token limit settings; scripts/llm_utils.py: create_chat_completion;
  scripts/commands.py: get_hyperlinks; scripts/chat.py: context construction and token
  management'
trigger_tests:
- '1) Setup deps and OPENAI_API_KEY; 2) Set FAST_TOKEN_LIMIT=2000 (lower than default
  4000); 3) Launch: python scripts/main.py --continuous --gpt3only; 4) Configure AI
  to analyze website with get_hyperlinks; 5) Execute get_hyperlinks on large website
  (e.g., mathrubhumi.com); 6) Observe "InvalidRequestError: This model''s maximum
  context length is 8191 tokens" when large link list exceeds token limit.'
