app: AutoGPTArenaHack
repo: https://github.com/ATheorell/AutoGPTArenaHack
commit: 1e4f2dc004b92b9f236543674f94fb9f0af9bb2e
defect_id: ATheorell-AutoGPTArenaHack-exceeding_llm_content_limit-case9
type: exceeding LLM content limit
case: '9'
consequence:
- ST
- IC
locations:
- autogpts/autogpt/autogpt/config/config.py; autogpts/autogpt/autogpt/plugins/__init__.py;
  autogpts/autogpt/autogpt/agents/base.py (build_prompt); autogpts/autogpt/autogpt/core/resource/model_providers/openai.py
  (count_message_tokens)
trigger_tests:
- '1. Run ''python -m autogpt --gpt3only'' 2. Create AI (Yoyo, Lua coder). 3. Authorize
  analyze_code then read_file/ingest_file/search_files on ''WoWinArabic_Chat.lua''.
  4. Observe: InvalidRequestError maximum context length 8191 (requested ~19023).
  Quick simulation: run ''python test_file_ops_token_overflow.py'' to reproduce overflow
  with concatenated tool outputs'
