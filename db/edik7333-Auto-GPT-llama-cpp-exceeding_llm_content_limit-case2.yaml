app: Auto-GPT-llama-cpp
repo: https://github.com/edik7333/Auto-GPT-llama-cpp
commit: 2b4bf189825c0abe28bf6f020b87921d82636d67
defect_id: edik7333-Auto-GPT-llama-cpp-exceeding_llm_content_limit-case2
type: exceeding LLM content limit
case: '2'
consequence:
- ST
- IC
locations:
- scripts/token_counter.py
trigger_tests:
- '1.Complete the environment setup for AutoGPT according to the instructions on this
  website: https://docs.agpt.co/autogpt/setup/ . (Open .env set USE_AZURE to True
  and make an Azure configuration file.Rename azure.yaml.template to azure.yaml and
  provide the relevant azure_api_base azure_api_version and deployment IDs for the
  models that you want to use. All these are also included in https://docs.agpt.co/autogpt/setup/
  ) 2.(cli mode)Use the command: "./autogpt.sh --continuous" to start AutoGPT in continuous
  mode. 3.Set up a simple task as blowe: Name: Phone finder Role: best phone 2 Goals:
  [''list 2 best phone for high mega pixel camera'' ''abort''] API Budget: infinite
  4.Allow AutoGPT to process the task and observe if the token length error occurs.'
